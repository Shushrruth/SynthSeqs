{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pytorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other helpful modules\n",
    "import time\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import single_letter_alphabet\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "x_train = np.load(\"/home/pbromley/generative_dhs/data_numpy/one_hot_seqs_train_100.npy\")\n",
    "y_train = np.load(\"/home/pbromley/generative_dhs/data_numpy/components_train_100.npy\")\n",
    "x_test = np.load(\"/home/pbromley/generative_dhs/data_numpy/one_hot_seqs_test_100.npy\")\n",
    "y_test = np.load(\"/home/pbromley/generative_dhs/data_numpy/components_test_100.npy\")\n",
    "\n",
    "y_train = y_train - 1       # raw component data goes from 1-15, want 0-14\n",
    "y_test = y_test - 1         # \"       \"       \"    \"    \"    \"     \"    \"\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 1, 100, 4)\n",
    "# x_train = x_train[y_train < 5]\n",
    "# y_train = y_train[y_train < 5]\n",
    "class_dist = np.bincount(y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For trying with fewer classes\n",
    "idx = np.array([(elt > 2.0) and (elt < 8.0) for elt in y_train])\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set Up Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the data (custom collate function for variable length inputs w/in batch)\n",
    "#   https://discuss.pytorch.org/t/how-to-create-a-dataloader-with-variable-size-input/8278/2\n",
    "\n",
    "# Custom dataset class to handle loading in of list of numpy arrays\n",
    "#   Makes it so don't have to write arrays to files and use DatasetFolder\n",
    "class DHSSequencesDataset(Dataset):\n",
    "    \"\"\"DHS sequences of varying length, as well as a component label\"\"\"\n",
    "\n",
    "    def __init__(self, seqs, components, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            seqs (list/np.array): List of one-hot numpy array DNA sequences\n",
    "            components (list/np.array): List of integers indicating components 1-15\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.seqs = seqs\n",
    "        self.components = components\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        one_hot = self.seqs[idx]\n",
    "        component = self.components[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(one_hot)\n",
    "\n",
    "        return one_hot, component\n",
    "    \n",
    "    \n",
    "# For loading batches with variable length inputs\n",
    "def collate_variable_length(batch):\n",
    "    one_hot = [sample[0] for sample in batch]\n",
    "    component = [sample[1] for sample in batch]\n",
    "    component = torch.LongTensor(component)\n",
    "    return [one_hot, component]\n",
    "\n",
    "\n",
    "\n",
    "dhs_dataset = DHSSequencesDataset(x_train, y_train)\n",
    "\n",
    "\n",
    "### Sample balanced class distribution\n",
    "class_weights = np.sum(class_dist) / class_dist    # calculate inverse probs\n",
    "weights = [class_weights[int(comp)] for _, comp in dhs_dataset]    # assign weight for every sample\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))  # create sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### For Uniform Length ######\n",
    "dhs_dataloader = DataLoader(dataset=dhs_dataset, \n",
    "                            batch_size=128,\n",
    "                            sampler=sampler)\n",
    "\n",
    "###### For Variable Length ######\n",
    "# dhs_dataloader = DataLoader(dataset=dhs_dataset, \n",
    "#                             batch_size=4,\n",
    "#                             shuffle=True,\n",
    "#                             collate_fn=collate_variable_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cdcgan_generator(nn.Module):\n",
    "    def __init__(self, channels, nz, num_classes):\n",
    "        super(cdcgan_generator, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(num_classes, num_classes//2)\n",
    "        \n",
    "        self.fc = nn.Linear(nz+(num_classes//2), 256*12*1)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=(7, 1), stride=2,\n",
    "                     padding=(2, 0), bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=(8, 1), stride=2,\n",
    "                     padding=(3, 0), bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=(8, 1), stride=2,\n",
    "                     padding=(3, 0), bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(32, channels, kernel_size=(16, 4), stride=2,\n",
    "                     padding=(7, 0), bias=False),\n",
    "            nn.Softmax(dim=3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, noise, label):\n",
    "        embed = self.embed(label)\n",
    "        concat = torch.cat([noise, embed], 1)\n",
    "        fc = self.fc(concat).view(-1, 256, 12, 1)\n",
    "        output = self.net(fc)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class cdcgan_discriminator(nn.Module):\n",
    "    def __init__(self, channels, num_classes):\n",
    "        super(cdcgan_discriminator, self).__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "        \n",
    "        self.embed = nn.Embedding(num_classes, 10)\n",
    "        \n",
    "        self.label_upsample = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 8, (20, 1), 10, (5, 0), bias=False),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(8, 1, (8, 4), 2, (3, 0), bias=False),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(channels+1, 32, kernel_size=(15, 4), stride=1, padding=(7, 0), bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.Conv2d(32, 64, kernel_size=(8, 1), stride=2, padding=(3, 0), bias=False), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 128, kernel_size=(8, 1), stride=2, padding=(3, 0), bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 256, kernel_size=(8, 1), stride=2, padding=(3, 0), bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 1, kernel_size=(25, 1), stride=1, padding=(0, 0), bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, seq, label):\n",
    "        embed = self.embed(label).view(-1, 1, 10, 1)\n",
    "        label_matrix = self.label_upsample(embed)\n",
    "        concat = torch.cat([seq.view(-1, 1, 200, 4), label_matrix], 1)\n",
    "        output = self.net(concat).squeeze()\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class DHS_cDCGAN():\n",
    "    def __init__(self, channels, bs, nz, nc, dataloader, use_cuda=True, init_weights=False):\n",
    "        \n",
    "        self.channels = channels\n",
    "        self.bs = bs\n",
    "        self.nz = nz\n",
    "        self.nc = nc\n",
    "        self.dataloader = dataloader\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        \n",
    "        self.G = cdcgan_generator(self.channels, self.nz, self.nc).to(self.device)\n",
    "        self.D = cdcgan_discriminator(self.channels, self.nc).to(self.device)\n",
    "        \n",
    "        self.criterion = nn.BCELoss().to(self.device)\n",
    "        self.optD = optim.Adam(self.D.parameters(), lr=0.0002, betas=(0.5, 0.99))\n",
    "        self.optG = optim.Adam(self.G.parameters(), lr=0.001, betas=(0.5, 0.99))\n",
    "        \n",
    "        for l in [self.G, self.D]:\n",
    "            if init_weights:\n",
    "                l.apply(self.weights_init)\n",
    "        \n",
    "        self.train_hist = {}\n",
    "        self.train_hist['d_loss'] = []\n",
    "        self.train_hist['g_loss'] = []\n",
    "        self.train_hist['epoch_time'] = []\n",
    "        self.train_hist['total_time'] = []\n",
    "        \n",
    "        \n",
    "    def weights_init(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            m.weight.detach().normal_(0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            m.weight.detach().normal_(1.0, 0.02)\n",
    "            m.bias.detach().fill_(0)\n",
    "        \n",
    "        \n",
    "    def create_fixed_inputs(self, num_total_imgs):\n",
    "        # For saving imgs\n",
    "        fixed_noise = torch.Tensor(num_total_imgs, self.nz).normal_(0, 1).to(self.device)\n",
    "\n",
    "        np_fixed_c = np.arange(0, self.nc, 1)\n",
    "        fixed_c = torch.from_numpy(np.repeat(np_fixed_c, num_total_imgs//self.nc, axis=0)).long().to(self.device)\n",
    "\n",
    "        return fixed_noise, fixed_c\n",
    "        \n",
    "    \n",
    "    def update_train_hist(self, d_loss, g_loss):\n",
    "        self.train_hist['d_loss'].append(d_loss.item())\n",
    "        self.train_hist['g_loss'].append(g_loss.item())\n",
    "        \n",
    "    \n",
    "    def plot_loss(self, path):\n",
    "        x = range(len(self.train_hist['d_loss']))\n",
    "        d_loss_hist = self.train_hist['d_loss']\n",
    "        g_loss_hist = self.train_hist['g_loss']\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(x, d_loss_hist, label='d_loss')\n",
    "        plt.plot(x, g_loss_hist, label='g_loss')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc=4)\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "    \n",
    "    \n",
    "    def save_imgs(self, f_noise, f_c, epoch):\n",
    "        with torch.no_grad():\n",
    "            images = self.G(f_noise, f_c)\n",
    "        to_save = images.transpose(2, 3)\n",
    "        img_path = '/home/pbromley/generative_dhs/images/pytorch-cdcgan-dhs-200/%d.png' % epoch\n",
    "        vutils.save_image(to_save, img_path, nrow=1, normalize=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def train(self, epochs=100, save_model=False, plot_loss=False):\n",
    "\n",
    "        noise = torch.zeros(self.bs, self.nz).to(self.device)\n",
    "        label = torch.zeros(self.bs).to(self.device)\n",
    "        \n",
    "        fixed_noise, fixed_c = self.create_fixed_inputs(45)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            noise.resize_(self.bs, self.nz)\n",
    "            label.resize_(self.bs)\n",
    "            epoch_start_time = time.time()\n",
    "            for i, (x, c) in enumerate(self.dataloader):\n",
    "                \n",
    "                # DISCRIMINATOR\n",
    "                self.optD.zero_grad()\n",
    "                x, c = x.float().to(self.device), c.long().to(self.device)\n",
    "                \n",
    "                if x.size(0) != self.bs:\n",
    "                    noise.resize_(x.size(0), self.nz)\n",
    "                    label.resize_(x.size(0))\n",
    "                \n",
    "                pred_real = self.D(x, c)\n",
    "                label.fill_(1)\n",
    "                d_loss_real = self.criterion(pred_real, label)\n",
    "                d_loss_real.backward()\n",
    "                \n",
    "                noise.normal_(0, 1)\n",
    "                fake = self.G(noise, c)\n",
    "                pred_fake = self.D(fake.detach(), c)\n",
    "                label.fill_(0)\n",
    "                d_loss_fake = self.criterion(pred_fake, label)\n",
    "                d_loss_fake.backward()\n",
    "                \n",
    "                d_loss_total = d_loss_real + d_loss_fake\n",
    "                \n",
    "                self.optD.step()\n",
    "                \n",
    "                \n",
    "                # GENERATOR\n",
    "                self.optG.zero_grad()\n",
    "                pred_g = self.D(fake, c)\n",
    "                label.fill_(1)\n",
    "                g_loss = self.criterion(pred_g, label)\n",
    "                \n",
    "                g_loss.backward()\n",
    "                \n",
    "                self.optG.step()\n",
    "                \n",
    "                \n",
    "                if plot_loss:\n",
    "                    self.update_train_hist(d_loss_total, g_loss)\n",
    "                    \n",
    "                if i % 1000 == 0:\n",
    "                    print('Epoch/Iter:{0}/{1}, Dloss: {2}, Gloss: {3}'.format(\n",
    "                            epoch, i, d_loss_total.item(), g_loss.item())\n",
    "                         )\n",
    "            \n",
    "            self.save_imgs(fixed_noise, fixed_c, epoch)\n",
    "            self.train_hist['epoch_time'].append(time.time() - epoch_start_time)\n",
    "            print(\"Time to complete epoch: \" + str(self.train_hist['epoch_time'][-1]))\n",
    "            \n",
    "            \n",
    "        print(\"Training is complete!\")\n",
    "        if save_model:\n",
    "            path = \"/home/pbromley/generative_dhs/saved_models/pytorch-cdcgan-dhs-200\"\n",
    "            print(\"Saving Model Weights...\")\n",
    "            torch.save(self.G.state_dict(), path + \"-g.pth\")\n",
    "            torch.save(self.D.state_dict(), path + \"-d.pth\")\n",
    "            print(\"Saved Model Weights\")\n",
    "\n",
    "        self.train_hist['total_time'].append(time.time() - start_time)\n",
    "        print(\"Total training time (%d epochs): \" % epochs + str(self.train_hist['total_time'][0]))\n",
    "        avg_epoch_time = np.mean(self.train_hist['epoch_time'])\n",
    "        print(\"Average time for each epoch: %.2f\" % avg_epoch_time)\n",
    "\n",
    "        if plot_loss:\n",
    "            self.plot_loss(\"/home/pbromley/generative_dhs/loss_plots/pytorch-cdcgan-dhs-200.png\")\n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class twoNgan_generator(nn.Module):\n",
    "    def __init__(self, channels, nz, num_classes):\n",
    "        super(twoNgan_generator, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(num_classes, num_classes//2)\n",
    "        \n",
    "        self.fc = nn.Linear(nz+(num_classes//2), 64*12*1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=(7, 1), stride=2,\n",
    "                     padding=(2, 0), bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=(8, 1), stride=2,\n",
    "                     padding=(3, 0), bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=(8, 1), stride=2,\n",
    "                     padding=(3, 0), bias=False),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(8, channels, kernel_size=(16, 4), stride=2,\n",
    "                     padding=(7, 0), bias=False),\n",
    "            nn.Softmax(dim=3)\n",
    "            \n",
    "#             nn.ConvTranspose2d(256, 256, kernel_size=(40, 1), stride=40, bias=False),\n",
    "#             nn.ConvTranspose2d(256, 1, kernel_size=(25, 4), stride=1,\n",
    "#                      padding=(12, 0), bias=False),\n",
    "#             nn.Softmax(dim=3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, noise, label):\n",
    "        embed = self.embed(label)\n",
    "        concat = torch.cat([noise, embed], 1)\n",
    "        fc = self.fc(concat)\n",
    "        relu = self.relu(fc).view(-1, 64, 12, 1)\n",
    "        output = self.net(relu)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class twoNgan_discriminator(nn.Module):\n",
    "    def __init__(self, channels, num_classes):\n",
    "        super(twoNgan_discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, kernel_size=(15, 4), stride=1, padding=(7, 0), bias=False),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(32, 64, kernel_size=(15, 1), stride=3, padding=(8, 0), bias=False), \n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.Conv2d(64, 128, kernel_size=(15, 1), stride=3, padding=(8, 0), bias=False),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.BatchNorm2d(128),\n",
    "# #             nn.Conv2d(128, 256, kernel_size=(8, 1), stride=2, padding=(3, 0), bias=False),\n",
    "# #             nn.LeakyReLU(0.1, inplace=True),\n",
    "# #             nn.BatchNorm2d(256),\n",
    "#             nn.Conv2d(128, 256, kernel_size=(15, 1), stride=1, padding=(0, 0), bias=False),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(1, 320, kernel_size=(25, 4), stride=1, padding=(12, 0), bias=False),\n",
    "            nn.MaxPool2d(kernel_size=(40, 1)),\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "#             nn.Conv2d(128, 256, kernel_size=(9, 1), stride=1, padding=(4, 0), bias=False),\n",
    "#             nn.MaxPool2d(kernel_size=(4, 1)),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.dense_net = nn.Sequential(\n",
    "            nn.Linear(320*5, 256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes*2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(25, 4), padding=(12, 0)),\n",
    "            nn.MaxPool2d(kernel_size=(40, 1)),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(16 * 5, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 16 * 5)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        seq = self.stn(seq)\n",
    "        net = self.net(seq)\n",
    "        output = self.dense_net(net.view(-1, 320 * 5))\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class DHS_TwoNGAN():\n",
    "    def __init__(self, channels, bs, nz, nc, dataloader, use_cuda=True, init_weights=True):\n",
    "        \n",
    "        self.channels = channels\n",
    "        self.bs = bs\n",
    "        self.nz = nz\n",
    "        self.nc = nc\n",
    "        self.dataloader = dataloader\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        \n",
    "        self.G = twoNgan_generator(self.channels, self.nz, self.nc).to(self.device)\n",
    "        self.D = twoNgan_discriminator(self.channels, self.nc).to(self.device)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss().to(self.device)\n",
    "        self.optD = optim.Adam(self.D.parameters(), lr=0.0002, betas=(0.5, 0.99))\n",
    "        self.optG = optim.Adam(self.G.parameters(), lr=0.0002, betas=(0.5, 0.99))\n",
    "        \n",
    "        for l in [self.G, self.D]:\n",
    "            if init_weights:\n",
    "                l.apply(self.weights_init)\n",
    "        \n",
    "        self.train_hist = {}\n",
    "        self.train_hist['d_loss'] = []\n",
    "        self.train_hist['g_loss'] = []\n",
    "        self.train_hist['epoch_time'] = []\n",
    "        self.train_hist['total_time'] = []\n",
    "        \n",
    "        \n",
    "    def weights_init(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            m.weight.detach().normal_(0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            m.weight.detach().normal_(1.0, 0.02)\n",
    "            m.bias.detach().fill_(0)\n",
    "        \n",
    "        \n",
    "    def create_fixed_inputs(self, num_total_imgs):\n",
    "        # For saving imgs\n",
    "        fixed_noise = torch.Tensor(num_total_imgs, self.nz).normal_(0, 1).to(self.device)\n",
    "\n",
    "        np_fixed_c = np.arange(0, self.nc, 1)\n",
    "        fixed_c = torch.from_numpy(np.repeat(np_fixed_c, num_total_imgs//self.nc, axis=0)).long().to(self.device)\n",
    "\n",
    "        return fixed_noise, fixed_c\n",
    "        \n",
    "    \n",
    "    def update_train_hist(self, d_loss, g_loss):\n",
    "        self.train_hist['d_loss'].append(d_loss.item())\n",
    "        self.train_hist['g_loss'].append(g_loss.item())\n",
    "        \n",
    "    \n",
    "    def plot_loss(self, path):\n",
    "        x = range(len(self.train_hist['d_loss']))\n",
    "        d_loss_hist = self.train_hist['d_loss']\n",
    "        g_loss_hist = self.train_hist['g_loss']\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(x, d_loss_hist, label='d_loss')\n",
    "        plt.plot(x, g_loss_hist, label='g_loss')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc=4)\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "    \n",
    "    \n",
    "    def save_imgs(self, f_noise, f_c, epoch):\n",
    "        with torch.no_grad():\n",
    "            images = self.G(f_noise, f_c)\n",
    "        to_save = images.transpose(2, 3)\n",
    "        img_path = '/home/pbromley/generative_dhs/images/pytorch-twongan-dhs-200/2-%d.png' % epoch\n",
    "        vutils.save_image(to_save, img_path, nrow=1, normalize=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def train(self, epochs=100, save_model=False, plot_loss=False):\n",
    "\n",
    "        noise = torch.zeros(self.bs, self.nz).to(self.device)\n",
    "        \n",
    "        fixed_noise, fixed_c = self.create_fixed_inputs(45)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            noise.resize_(self.bs, self.nz)\n",
    "            epoch_start_time = time.time()\n",
    "            for i, (x, c) in enumerate(self.dataloader):\n",
    "                \n",
    "                # DISCRIMINATOR\n",
    "                self.optD.zero_grad()\n",
    "                x, c = x.float().to(self.device), c.long().to(self.device)\n",
    "                \n",
    "                if x.size(0) != self.bs:\n",
    "                    noise.resize_(x.size(0), self.nz)\n",
    "                \n",
    "                pred_real = self.D(x)\n",
    "                d_loss_real = self.criterion(pred_real, c)\n",
    "                d_loss_real.backward()\n",
    "                \n",
    "                noise.normal_(0, 1)\n",
    "                fake_c = torch.randint_like(c, 0, self.nc)               # fake random classes\n",
    "                fake_c_for_d = fake_c + self.nc                          # fake class to be fed to D loss calc\n",
    "                fake = self.G(noise, fake_c)\n",
    "                pred_fake = self.D(fake.detach())\n",
    "                d_loss_fake = self.criterion(pred_fake, fake_c_for_d)\n",
    "                d_loss_fake.backward()\n",
    "                \n",
    "                d_loss_total = d_loss_real + d_loss_fake\n",
    "                \n",
    "                self.optD.step()\n",
    "        \n",
    "                # GENERATOR\n",
    "                self.optG.zero_grad()\n",
    "                pred_g = self.D(fake)\n",
    "                g_loss = self.criterion(pred_g, fake_c)\n",
    "                \n",
    "                g_loss.backward()\n",
    "                \n",
    "                self.optG.step()\n",
    "                \n",
    "                \n",
    "                if plot_loss:\n",
    "                    self.update_train_hist(d_loss_total, g_loss)\n",
    "                    \n",
    "                if i % 2000 == 0:\n",
    "                    print('Epoch/Iter:{0}/{1}, Dloss: {2}, Gloss: {3}'.format(\n",
    "                            epoch, i, d_loss_total.item(), g_loss.item())\n",
    "                         )\n",
    "            \n",
    "            self.save_imgs(fixed_noise, fixed_c, epoch)\n",
    "            self.train_hist['epoch_time'].append(time.time() - epoch_start_time)\n",
    "            print(\"Time to complete epoch: \" + str(self.train_hist['epoch_time'][-1]))\n",
    "            \n",
    "            \n",
    "        print(\"Training is complete!\")\n",
    "        if save_model:\n",
    "            path = \"/home/pbromley/generative_dhs/saved_models/pytorch-twongan-dhs-200\"\n",
    "            print(\"Saving Model Weights...\")\n",
    "            torch.save(self.G.state_dict(), path + \"-g-2.pth\")\n",
    "            torch.save(self.D.state_dict(), path + \"-d-2.pth\")\n",
    "            print(\"Saved Model Weights\")\n",
    "\n",
    "        self.train_hist['total_time'].append(time.time() - start_time)\n",
    "        print(\"Total training time (%d epochs): \" % epochs + str(self.train_hist['total_time'][0]))\n",
    "        avg_epoch_time = np.mean(self.train_hist['epoch_time'])\n",
    "        print(\"Average time for each epoch: %.2f\" % avg_epoch_time)\n",
    "\n",
    "        if plot_loss:\n",
    "            self.plot_loss(\"/home/pbromley/generative_dhs/loss_plots/pytorch-twongan-dhs-200-2.png\")\n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class acgan_generator(nn.Module):\n",
    "    def __init__(self, channels, nz, num_classes):\n",
    "        super(acgan_generator, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(num_classes, num_classes//2)\n",
    "        \n",
    "        self.fc = nn.Linear(nz+(num_classes//2), 256*12*1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=(7, 1), stride=2,\n",
    "                     padding=(2, 0), bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=(8, 1), stride=2,\n",
    "                     padding=(3, 0), bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=(8, 1), stride=2,\n",
    "                     padding=(3, 0), bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(32, channels, kernel_size=(16, 4), stride=2,\n",
    "                     padding=(7, 0), bias=False),\n",
    "            nn.Softmax(dim=3)\n",
    "            \n",
    "#             nn.ConvTranspose2d(256, 256, kernel_size=(40, 1), stride=40, bias=False),\n",
    "#             nn.ConvTranspose2d(256, 1, kernel_size=(25, 4), stride=1,\n",
    "#                      padding=(12, 0), bias=False),\n",
    "#             nn.Softmax(dim=3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, noise, label):\n",
    "        embed = self.embed(label)\n",
    "        concat = torch.cat([noise, embed], 1)\n",
    "        fc = self.fc(concat)\n",
    "        relu = self.relu(fc).view(-1, 256, 12, 1)\n",
    "        output = self.net(relu)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class acgan_discriminator(nn.Module):\n",
    "    def __init__(self, channels, num_classes):\n",
    "        super(acgan_discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, kernel_size=(15, 4), stride=1, padding=(7, 0), bias=False),\n",
    "#             nn.LeakyReLU(0.1, inplace=True),\n",
    "#             nn.Conv2d(32, 64, kernel_size=(15, 1), stride=3, padding=(8, 0), bias=False), \n",
    "#             nn.LeakyReLU(0.1, inplace=True),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.Conv2d(64, 128, kernel_size=(15, 1), stride=3, padding=(8, 0), bias=False),\n",
    "#             nn.LeakyReLU(0.1, inplace=True),\n",
    "#             nn.BatchNorm2d(128),\n",
    "# #             nn.Conv2d(128, 256, kernel_size=(8, 1), stride=2, padding=(3, 0), bias=False),\n",
    "# #             nn.LeakyReLU(0.1, inplace=True),\n",
    "# #             nn.BatchNorm2d(256),\n",
    "#             nn.Conv2d(128, 256, kernel_size=(15, 1), stride=1, padding=(0, 0), bias=False),\n",
    "#             nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(1, 320, kernel_size=(25, 4), stride=1, padding=(12, 0), bias=False),\n",
    "            nn.MaxPool2d(kernel_size=(40, 1)),\n",
    "            nn.LayerNorm([320, 5, 1]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.dense_net = nn.Sequential(\n",
    "            nn.Linear(320*5, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        \n",
    "        self.pred = nn.Sequential(\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "        self.aux = nn.Sequential(\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        net = self.net(seq)\n",
    "        dense = self.dense_net(net.view(-1, 320 * 5))\n",
    "        pred = self.pred(dense)\n",
    "        aux = self.aux(dense)\n",
    "        return pred, aux\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class DHS_ACGAN():\n",
    "    def __init__(self, channels, bs, nz, nc, dataloader, use_cuda=True, init_weights=True):\n",
    "        \n",
    "        self.channels = channels\n",
    "        self.bs = bs\n",
    "        self.nz = nz\n",
    "        self.nc = nc\n",
    "        self.dataloader = dataloader\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        \n",
    "        self.G = acgan_generator(self.channels, self.nz, self.nc).to(self.device)\n",
    "        self.D = acgan_discriminator(self.channels, self.nc).to(self.device)\n",
    "        \n",
    "        self.criterion_pred = nn.BCELoss().to(self.device)\n",
    "        self.criterion_aux = nn.CrossEntropyLoss().to(self.device)\n",
    "        self.optD = optim.Adam(self.D.parameters(), lr=0.0002, betas=(0.5, 0.99))\n",
    "        self.optG = optim.Adam(self.G.parameters(), lr=0.0002, betas=(0.5, 0.99))\n",
    "        \n",
    "        for l in [self.G, self.D]:\n",
    "            if init_weights:\n",
    "                l.apply(self.weights_init)\n",
    "        \n",
    "        self.train_hist = {}\n",
    "        self.train_hist['d_loss'] = []\n",
    "        self.train_hist['g_loss'] = []\n",
    "        self.train_hist['epoch_time'] = []\n",
    "        self.train_hist['total_time'] = []\n",
    "        \n",
    "        \n",
    "    def weights_init(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            m.weight.detach().normal_(0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            m.weight.detach().normal_(1.0, 0.02)\n",
    "            m.bias.detach().fill_(0)\n",
    "        \n",
    "        \n",
    "    def create_fixed_inputs(self, num_total_imgs):\n",
    "        # For saving imgs\n",
    "        fixed_noise = torch.Tensor(num_total_imgs, self.nz).normal_(0, 1).to(self.device)\n",
    "\n",
    "        np_fixed_c = np.arange(0, self.nc, 1)\n",
    "        fixed_c = torch.from_numpy(np.repeat(np_fixed_c, num_total_imgs//self.nc, axis=0)).long().to(self.device)\n",
    "\n",
    "        return fixed_noise, fixed_c\n",
    "        \n",
    "    \n",
    "    def update_train_hist(self, d_loss, g_loss):\n",
    "        self.train_hist['d_loss'].append(d_loss.item())\n",
    "        self.train_hist['g_loss'].append(g_loss.item())\n",
    "        \n",
    "    \n",
    "    def plot_loss(self, path):\n",
    "        x = range(len(self.train_hist['d_loss']))\n",
    "        d_loss_hist = self.train_hist['d_loss']\n",
    "        g_loss_hist = self.train_hist['g_loss']\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(x, d_loss_hist, label='d_loss')\n",
    "        plt.plot(x, g_loss_hist, label='g_loss')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc=4)\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "    \n",
    "    \n",
    "    def save_imgs(self, f_noise, f_c, epoch):\n",
    "        with torch.no_grad():\n",
    "            images = self.G(f_noise, f_c)\n",
    "        to_save = images.transpose(2, 3)\n",
    "        img_path = '/home/pbromley/generative_dhs/images/pytorch-acgan-dhs-200/%d.png' % epoch\n",
    "        vutils.save_image(to_save, img_path, nrow=1, normalize=True)\n",
    "        \n",
    "    # From https://github.com/jalola/improved-wgan-pytorch/blob/master/congan_train.py\n",
    "    def calc_gradient_penalty(self, x, fake_x):\n",
    "        bs = x.size(0)\n",
    "        alpha = torch.rand(bs, 1)\n",
    "        alpha = alpha.expand(bs, int(x.nelement()/bs)).contiguous()\n",
    "        alpha = alpha.view(bs, 1, 200, 4)\n",
    "        alpha = alpha.to(self.device)\n",
    "\n",
    "        fake_x = fake_x.view(bs, 1, 200, 4)\n",
    "        interpolates = alpha * x.detach() + ((1 - alpha) * fake_x.detach())\n",
    "\n",
    "        interpolates = interpolates.to(self.device)\n",
    "        interpolates.requires_grad_(True)   \n",
    "\n",
    "        disc_interpolates, _ = self.D(interpolates)\n",
    "\n",
    "        gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                                  grad_outputs=torch.ones(disc_interpolates.size()).to(self.device),\n",
    "                                  create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "        gradients = gradients.view(gradients.size(0), -1)                              \n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n",
    "        return gradient_penalty\n",
    "        \n",
    "        \n",
    "    \n",
    "    def train(self, epochs=100, save_model=False, plot_loss=False):\n",
    "\n",
    "        noise = torch.zeros(self.bs, self.nz).to(self.device)\n",
    "        label = torch.zeros(self.bs).to(self.device)\n",
    "        \n",
    "        fixed_noise, fixed_c = self.create_fixed_inputs(45)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            for i, (x, c) in enumerate(self.dataloader):\n",
    "                \n",
    "                \n",
    "                self.optD.zero_grad()\n",
    "                x, c = x.float().to(self.device), c.long().to(self.device)\n",
    "                bs = x.size(0)//5\n",
    "                \n",
    "                # GENERATOR\n",
    "                self.optG.zero_grad()\n",
    "                \n",
    "                noise.resize_(bs, self.nz)\n",
    "                \n",
    "\n",
    "                noise.normal_(0, 1)\n",
    "                fake_c = torch.randint_like(c[0:bs], 0, self.nc)               # fake random classes\n",
    "                fake = self.G(noise, fake_c)\n",
    "                \n",
    "                pred_g, pred_g_aux = self.D(fake)\n",
    "             \n",
    "                g_loss_pred = -pred_g.mean()\n",
    "                g_loss_aux = self.criterion_aux(pred_g_aux, fake_c).mean()\n",
    "                g_loss = g_loss_pred + g_loss_aux\n",
    "                g_loss.backward()\n",
    "                \n",
    "                self.optG.step()\n",
    "                \n",
    "                \n",
    "                # DISCRIMINATOR\n",
    "                for j in range(5):\n",
    "                    batch = x[((j)*bs):((j+1)*bs)]\n",
    "                    pred_real, pred_real_aux = self.D(batch)\n",
    "                 \n",
    "                    d_loss_real_pred = pred_real.mean()\n",
    "                    d_loss_real_aux = self.criterion_aux(pred_real_aux, c[(j)*bs:(j+1)*bs]).mean()\n",
    "                    \n",
    "                    noise.normal_(0, 1)\n",
    "                    fake_c_d = torch.randint_like(fake_c, 0, self.nc)\n",
    "                    fake_d = self.G(noise, fake_c_d)\n",
    "                    \n",
    "                    pred_fake, pred_fake_aux = self.D(fake_d.detach())\n",
    "                    d_loss_fake_pred = pred_fake.mean()\n",
    "                    gradient_penalty = self.calc_gradient_penalty(batch, fake_d)\n",
    "\n",
    "                    d_loss_total = d_loss_fake_pred - d_loss_real_pred + gradient_penalty + d_loss_real_aux\n",
    "                    d_loss_total.backward()\n",
    "                    w_dist = d_loss_fake_pred - d_loss_real_pred\n",
    "\n",
    "                    self.optD.step()\n",
    "        \n",
    "                \n",
    "                \n",
    "                \n",
    "                if plot_loss:\n",
    "                    self.update_train_hist(d_loss_total, g_loss)\n",
    "                    \n",
    "                if i % 200 == 0:\n",
    "                    print('Epoch/Iter:{0}/{1}, Dloss: {2}, Gloss: {3}, WDist: {4}'.format(\n",
    "                            epoch, i, d_loss_total.item(), g_loss.item(), w_dist.item())\n",
    "                         )\n",
    "            \n",
    "            self.save_imgs(fixed_noise, fixed_c, epoch)\n",
    "            self.train_hist['epoch_time'].append(time.time() - epoch_start_time)\n",
    "            print(\"Time to complete epoch: \" + str(self.train_hist['epoch_time'][-1]))\n",
    "            \n",
    "            \n",
    "        print(\"Training is complete!\")\n",
    "        if save_model:\n",
    "            path = \"/home/pbromley/generative_dhs/saved_models/pytorch-acgan-dhs-200\"\n",
    "            print(\"Saving Model Weights...\")\n",
    "            torch.save(self.G.state_dict(), path + \"-g.pth\")\n",
    "            torch.save(self.D.state_dict(), path + \"-d.pth\")\n",
    "            print(\"Saved Model Weights\")\n",
    "\n",
    "        self.train_hist['total_time'].append(time.time() - start_time)\n",
    "        print(\"Total training time (%d epochs): \" % epochs + str(self.train_hist['total_time'][0]))\n",
    "        avg_epoch_time = np.mean(self.train_hist['epoch_time'])\n",
    "        print(\"Average time for each epoch: %.2f\" % avg_epoch_time)\n",
    "\n",
    "        if plot_loss:\n",
    "            self.plot_loss(\"/home/pbromley/generative_dhs/loss_plots/pytorch-acgan-dhs-200.png\")\n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_cdcgan = DHS_cDCGAN(1, 128, 100, 15, \n",
    "                        dhs_dataloader, init_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dhs_cdcgan.train(epochs=50, save_model=True, plot_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_twongan = DHS_TwoNGAN(1, 128, 70, 15, dhs_dataloader, init_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_twongan.train(epochs=50, save_model=True, plot_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_acgan = DHS_ACGAN(1, 128, 500, 15, dhs_dataloader, init_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_acgan.train(epochs=50, save_model=True, plot_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhs_twongan.D.to(\"cpu\")\n",
    "dhs_twongan.D.double()\n",
    "# D = twoNgan_discriminator(1, 15)\n",
    "# D.load_state_dict(torch.load(\"/home/pbromley/generative_dhs/saved_models/pytorch-twongan-dhs-200-d.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dhs_twongan.D(torch.from_numpy((x_train).reshape(-1, 1, 200, 4)[10000:15000]))\n",
    "\n",
    "target = torch.from_numpy(y_train[10000:15000]).long()\n",
    "\n",
    "max_index = pred.max(dim=1)[1]\n",
    "\n",
    "(max_index == target).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = dhs_twongan.D.state_dict()['net.0.weight'].data.cpu().numpy()\n",
    "filters = filters.squeeze()\n",
    "f, ax = plt.subplots(5, 5, figsize=(50, 50))\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        ax[i][j].imshow(filters[i*5+j].transpose(), vmin=0, cmap=\"Greens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pretrained models if necessary\n",
    "# G = cdcgan_generator(1, 100, 15)\n",
    "# D = cdcgan_discriminator(1, 15)\n",
    "# G.load_state_dict(torch.load(\"/home/pbromley/generative_dhs/saved_models/pytorch-cdcgan-dhs-200-g.pth\"))\n",
    "# D.load_state_dict(torch.load(\"/home/pbromley/generative_dhs/saved_models/pytorch-cdcgan-dhs-200-d.pth\"))\n",
    "\n",
    "# Otherwise get G and D weights from trained model class\n",
    "G = dhs_twongan.G\n",
    "D = dhs_twongan.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(\"/home/pbromley/generative_dhs/saved_models/pytorch-twongan-dhs-200-d.pth\").keys()#['dense_net.1.weight'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.double()\n",
    "G.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G.state_dict()['net.9.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = G.state_dict()['conv3.weight'].data.cpu().numpy()\n",
    "filters = filters.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(5, 5, figsize=(50, 50))\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        ax[i][j].imshow(filters[i*5+j].transpose(), vmin=0, cmap=\"Greens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.from_numpy(np.random.normal(0, 1, (75000, 100)))\n",
    "components = torch.from_numpy(np.repeat(np.arange(15), 5000)).long()\n",
    "with torch.no_grad():\n",
    "    one_hot_seqs = G(noise, components).numpy()\n",
    "\n",
    "one_hot_seqs = one_hot_seqs.reshape(-1, 200, 4)\n",
    "    \n",
    "def one_hot_to_seq(one_hot):\n",
    "    order_dict = {0:'A', 1:'T', 2:'C', 3:'G'}\n",
    "    seq = \"\"\n",
    "    idxs = np.argmax(one_hot, axis=1)\n",
    "    for elt in idxs:\n",
    "        seq += order_dict[elt]\n",
    "    return Seq(seq, single_letter_alphabet)\n",
    "\n",
    "print(\"Converting one-hot to normal...\")\n",
    "seqs = [one_hot_to_seq(one_hot_seq) for one_hot_seq in one_hot_seqs]\n",
    "components = components.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(one_hot_seqs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs = [\"GGCGC\", \"ATGAGTCAT\", \"CGAAACCGAAAC\", \"TGATGCAA\", \"ATGA\", \"ATTGT\",\n",
    "          \"AACCGGTT\", \"AATTA\", \"AAATAG\", \"GTCACGCTT\", \"GTAAACA\", \"AACAGCTGT\", \"CAAAGT\", \"CGGAT\",\n",
    "          \"ACTTCC\"]\n",
    "motifs = [Seq(motif, single_letter_alphabet) for motif in motifs]\n",
    "\n",
    "# def motif_search(seqs, components, motifs):\n",
    "count_dict = {num:np.zeros(15) for num in range(15)}\n",
    "print(\"Motif: \", end=\" \")\n",
    "for i, motif in enumerate(motifs):\n",
    "    print(str(i) + \":\" + motif, end=' ')\n",
    "    for j, seq in enumerate(seqs):\n",
    "        count_dict[components[j]][i] += seq.count(motif)\n",
    "\n",
    "count_mat = np.array(list(count_dict.values()))   \n",
    "plt.xticks(np.arange(15), [str(x+1) for x in range(15)])\n",
    "plt.yticks(np.arange(15), [str(x+1) for x in range(15)])\n",
    "plt.imshow(count_mat/count_mat.max(axis=0), cmap='Greens')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Motifs (for each component)\")\n",
    "plt.ylabel(\"Sequences (separated by component)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "# motif_search(seqs, components, motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, linewidth=250)\n",
    "count_mat/count_mat.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALIGNMENT SCORE\n",
    "from Bio import pairwise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise2.align.globalxx(seqs[0], seqs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_sum = {k:0 for k in range(15)}\n",
    "totals = {k:0 for k in range(15)}\n",
    "for i in range(50000):\n",
    "    align_sum[y_train[i+1]] += pairwise2.align.globalxx(x_train_seqs[0], x_train_seqs[i+1], score_only=True)\n",
    "    totals[y_train[i+1]] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[align_sum[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seqs = [one_hot_to_seq(x_one_hot_seq) for x_one_hot_seq in x_train.reshape(-1, 200, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise2.align.globalxx(x_train_seqs[-2], x_train_seqs[-1], score_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(np.random.normal(0, 1, (75000, 100))).requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mat.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_seqs(seqs, idx):\n",
    "    num_seqs = len(idx)\n",
    "    f, ax = plt.subplots(num_seqs, figsize=(10, 2*num_seqs), sharex=True)\n",
    "    for i in idx:\n",
    "        if num_seqs > 1:\n",
    "            ax[i].imshow(x_train[i].transpose(), cmap=\"Blues\")\n",
    "        else:\n",
    "            ax.imshow(x_train[idx[0]].transpose(), cmap=\"Blues\")  \n",
    "    f.subplots_adjust(bottom=0.7)\n",
    "    f.savefig(\"/home/pbromley/test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, figsize=(100, 4), sharex=True)\n",
    "for i in range(2):\n",
    "    ax[i].imshow(x_train[i].transpose(), cmap=\"Blues\")\n",
    "plt.subplots_adjust(bottom=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(dhs_cdcgan.train_hist['d_loss']))\n",
    "d_loss_hist = dhs_cdcgan.train_hist['d_loss']\n",
    "g_loss_hist = dhs_cdcgan.train_hist['g_loss']\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(x, [float(d.cpu()) for d in d_loss_hist], label='d_loss')\n",
    "# plt.scatter(x, [float(g.cpu()) for g in g_loss_hist], label='g_loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc=4)\n",
    "plt.savefig(\"/home/pbromley/generative_dhs/loss_plots/pytorch-cdcgan-dhs-200-d.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=(7, 1), stride=2,\n",
    "                     padding=(2, 0), bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=(8, 1), stride=2,\n",
    "                     padding=(3, 0), bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=(8, 1), stride=2,\n",
    "                     padding=(3, 0), bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=(16, 4), stride=2,\n",
    "                     padding=(7, 0), bias=False),\n",
    "            nn.Softmax(dim=3)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x(Variable(torch.rand(1, 256, 12, 1))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =nn.Embedding(15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x(Variable(torch.LongTensor([1]))).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(15, 4), stride=1, padding=(7, 0), bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=(15, 1), stride=3, padding=(8, 0), bias=False), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 128, kernel_size=(15, 1), stride=3, padding=(8, 0), bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "#             nn.Conv2d(128, 256, kernel_size=(8, 1), stride=2, padding=(3, 0), bias=False),\n",
    "#             nn.LeakyReLU(0.1, inplace=True),\n",
    "#             nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(128, 256, kernel_size=(15, 1), stride=1, padding=(0, 0), bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "#             nn.ConvTranspose2d(256, 256, kernel_size=(40, 1), stride=40, bias=False),\n",
    "#             nn.ConvTranspose2d(256, 1, kernel_size=(25, 4), stride=1,\n",
    "#                      padding=(12, 0), bias=False),\n",
    "#             nn.Softmax(dim=3)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x(torch.rand(1, 1, 200, 4)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "320 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(800, 400)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.bn = nn.BatchNorm1d(400)\n",
    "        self.fc21 = nn.Linear(400, 200)\n",
    "        self.fc22 = nn.Linear(400, 200)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        fc1 = self.fc1(x)\n",
    "        relu = self.relu(fc1)\n",
    "        bn = self.bn(relu)\n",
    "        fc21 = self.fc21(bn)\n",
    "        fc22 = self.fc22(bn)\n",
    "        return fc21, fc22\n",
    "    \n",
    "\n",
    "class decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(200, 400)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.bn = nn.BatchNorm1d(400)\n",
    "        self.fc2 = nn.Linear(400, 800)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "        \n",
    "    def forward(self, z):\n",
    "        fc1 = self.fc1(z)\n",
    "        relu = self.relu(fc1)\n",
    "        bn = self.bn(relu)\n",
    "        fc2 = self.fc2(bn).view(-1, 200, 4)\n",
    "        softmax = self.softmax(fc2)\n",
    "        return softmax\n",
    "    \n",
    "    \n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder()\n",
    "        self.decoder = decoder()\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x.view(-1, 800))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "    \n",
    "\n",
    "device = \"cuda\"\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar, bs):\n",
    "    BCE = F.binary_cross_entropy(recon_x.view(-1, 800), x.view(-1, 800))\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    # Normalise by same number of elements as in reconstruction\n",
    "    KLD /= bs * 784\n",
    "  \n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "def save_imgs(real_x, epoch):\n",
    "    with torch.no_grad():\n",
    "        recon_x, _, _ = model(real_x)\n",
    "    to_save = recon_x.transpose(1, 2).view(-1, 1, 4, 200)\n",
    "    img_path_real = '/home/pbromley/generative_dhs/images/pytorch-vae-dhs-200/real-%d.png' % epoch\n",
    "    img_path_fake = '/home/pbromley/generative_dhs/images/pytorch-vae-dhs-200/fake-%d.png' % epoch\n",
    "    vutils.save_image(real_x.transpose(1, 2).view(-1, 1, 4, 200), img_path_real, nrow=1, normalize=True)\n",
    "    vutils.save_image(to_save, img_path_fake, nrow=1, normalize=True)\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch, save):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(dhs_dataloader):\n",
    "        data = data.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar, data.size(0))\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dhs_dataloader.dataset),\n",
    "                100. * batch_idx / len(dhs_dataloader),\n",
    "                loss.item() / len(data)))\n",
    "        \n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(dhs_dataloader.dataset)))\n",
    "    save_imgs(save, epoch)\n",
    "    \n",
    "\n",
    "\n",
    "# def test(epoch):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for i, (data, _) in enumerate(test_loader):\n",
    "#             data = data.to(device)\n",
    "#             recon_batch, mu, logvar = model(data)\n",
    "#             test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "#             if i == 0:\n",
    "#                 n = min(data.size(0), 8)\n",
    "#                 comparison = torch.cat([data[:n],\n",
    "#                                       recon_batch.view(args.batch_size, 1, 28, 28)[:n]])\n",
    "#                 save_image(comparison.cpu(),\n",
    "#                          'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "#     print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "save = torch.from_numpy(x_test[0:10]).float().to(device)\n",
    "for epoch in range(50):\n",
    "    train(epoch, save)\n",
    "    \n",
    "#     test(epoch)\n",
    "#     with torch.no_grad():\n",
    "#         sample = torch.randn(64, 20).to(device)\n",
    "#         sample = model.decode(sample).cpu()\n",
    "#         save_image(sample.view(64, 1, 28, 28),\n",
    "#                    'results/sample_' + str(epoch) + '.png')\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SN-GAN w/ Projection Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful PyTorch code from external sources:\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "##                            Conditional Batch Norm                             ##\n",
    "## (https://github.com/ap229997/Conditional-Batch-Norm/blob/master/model/cbn.py) ##\n",
    "###################################################################################\n",
    "'''\n",
    "CBN (Conditional Batch Normalization layer)\n",
    "    uses an MLP to predict the beta and gamma parameters in the batch norm equation\n",
    "    Reference : https://papers.nips.cc/paper/7237-modulating-early-visual-processing-by-language.pdf\n",
    "'''\n",
    "class CBN(nn.Module):\n",
    "\n",
    "    def __init__(self, lstm_size, emb_size, out_size, use_betas=True, use_gammas=True, eps=1.0e-5):\n",
    "        super(CBN, self).__init__()\n",
    "\n",
    "        self.lstm_size = lstm_size # size of the lstm emb which is input to MLP\n",
    "        self.emb_size = emb_size # size of hidden layer of MLP\n",
    "        self.out_size = out_size # output of the MLP - for each channel\n",
    "        self.use_betas = use_betas\n",
    "        self.use_gammas = use_gammas\n",
    "\n",
    "        self.batch_size = 16\n",
    "        self.channels = out_size\n",
    "        self.height = 100\n",
    "        self.width = 4\n",
    "\n",
    "        # beta and gamma parameters for each channel - defined as trainable parameters\n",
    "        self.betas = nn.Parameter(torch.zeros(self.batch_size, self.channels).cuda())\n",
    "        self.gammas = nn.Parameter(torch.ones(self.batch_size, self.channels).cuda())\n",
    "        self.eps = eps\n",
    "\n",
    "        # MLP used to predict betas and gammas\n",
    "        self.fc_gamma = nn.Sequential(\n",
    "            nn.Linear(self.lstm_size, self.emb_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.emb_size, self.out_size),\n",
    "            ).cuda()\n",
    "\n",
    "        self.fc_beta = nn.Sequential(\n",
    "            nn.Linear(self.lstm_size, self.emb_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.emb_size, self.out_size),\n",
    "            ).cuda()\n",
    "\n",
    "        # initialize weights using Xavier initialization and biases with constant value\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "    '''\n",
    "    Predicts the value of delta beta and delta gamma for each channel\n",
    "    Arguments:\n",
    "        lstm_emb : lstm embedding of the question\n",
    "    Returns:\n",
    "        delta_betas, delta_gammas : for each layer\n",
    "    '''\n",
    "    def create_cbn_input(self, lstm_emb):\n",
    "\n",
    "        if self.use_betas:\n",
    "            delta_betas = self.fc_beta(lstm_emb)\n",
    "        else:\n",
    "            delta_betas = torch.zeros(self.batch_size, self.channels).cuda()\n",
    "\n",
    "        if self.use_gammas:\n",
    "            delta_gammas = self.fc_gamma(lstm_emb)\n",
    "        else:\n",
    "            delta_gammas = torch.zeros(self.batch_size, self.channels).cuda()\n",
    "\n",
    "        return delta_betas, delta_gammas\n",
    "\n",
    "    '''\n",
    "    Computer Normalized feature map with the updated beta and gamma values\n",
    "    Arguments:\n",
    "        feature : feature map from the previous layer\n",
    "        lstm_emb : lstm embedding of the question\n",
    "    Returns:\n",
    "        out : beta and gamma normalized feature map\n",
    "        lstm_emb : lstm embedding of the question (unchanged)\n",
    "    Note : lstm_emb needs to be returned since CBN is defined within nn.Sequential\n",
    "           and subsequent CBN layers will also require lstm question embeddings\n",
    "    '''\n",
    "    def forward(self, feature, lstm_emb):\n",
    "        self.batch_size, self.channels, self.height, self.width = feature.data.shape\n",
    "\n",
    "        # get delta values\n",
    "        delta_betas, delta_gammas = self.create_cbn_input(lstm_emb)\n",
    "        \n",
    "        self.betas.data.resize_(self.batch_size, self.channels)\n",
    "        self.gammas.data.resize_(self.batch_size, self.channels)\n",
    "\n",
    "        betas_cloned = self.betas.clone()\n",
    "        gammas_cloned = self.gammas.clone()\n",
    "        \n",
    "        # update the values of beta and gamma\n",
    "        betas_cloned += delta_betas\n",
    "        gammas_cloned += delta_gammas\n",
    "\n",
    "        # get the mean and variance for the batch norm layer\n",
    "        batch_mean = torch.mean(feature)\n",
    "        batch_var = torch.var(feature)\n",
    "\n",
    "        # extend the betas and gammas of each channel across the height and width of feature map\n",
    "        betas_expanded = torch.stack([betas_cloned]*self.height, dim=2)\n",
    "        betas_expanded = torch.stack([betas_expanded]*self.width, dim=3)\n",
    "\n",
    "        gammas_expanded = torch.stack([gammas_cloned]*self.height, dim=2)\n",
    "        gammas_expanded = torch.stack([gammas_expanded]*self.width, dim=3)\n",
    "\n",
    "        # normalize the feature map\n",
    "        feature_normalized = (feature-batch_mean)/torch.sqrt(batch_var+self.eps)\n",
    "\n",
    "        # get the normalized feature map with the updated beta and gamma values\n",
    "        out = torch.mul(feature_normalized, gammas_expanded) + betas_expanded\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "###################################################################################################################\n",
    "##                                                  Spectral Norm                                                ##\n",
    "## https://github.com/christiancosgrove/pytorch-spectral-normalization-gan/blob/master/spectral_normalization.py ##\n",
    "###################################################################################################################\n",
    "\n",
    "def l2normalize(v, eps=1e-12):\n",
    "    return v / (v.norm() + eps)\n",
    "\n",
    "\n",
    "class SpectralNorm(nn.Module):\n",
    "    def __init__(self, module, name='weight', power_iterations=1):\n",
    "        super(SpectralNorm, self).__init__()\n",
    "        self.module = module\n",
    "        self.name = name\n",
    "        self.power_iterations = power_iterations\n",
    "        if not self._made_params():\n",
    "            self._make_params()\n",
    "\n",
    "    def _update_u_v(self):\n",
    "        u = getattr(self.module, self.name + \"_u\")\n",
    "        v = getattr(self.module, self.name + \"_v\")\n",
    "        w = getattr(self.module, self.name + \"_bar\")\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        for _ in range(self.power_iterations):\n",
    "            v.data = l2normalize(torch.mv(torch.t(w.view(height,-1).data), u.data))\n",
    "            u.data = l2normalize(torch.mv(w.view(height,-1).data, v.data))\n",
    "\n",
    "        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\n",
    "        sigma = u.dot(w.view(height, -1).mv(v))\n",
    "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
    "\n",
    "    def _made_params(self):\n",
    "        try:\n",
    "            u = getattr(self.module, self.name + \"_u\")\n",
    "            v = getattr(self.module, self.name + \"_v\")\n",
    "            w = getattr(self.module, self.name + \"_bar\")\n",
    "            return True\n",
    "        except AttributeError:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def _make_params(self):\n",
    "        w = getattr(self.module, self.name)\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        width = w.view(height, -1).data.shape[1]\n",
    "\n",
    "        u = nn.Parameter(w.data.new(height).normal_(0, 1), requires_grad=True)\n",
    "        v = nn.Parameter(w.data.new(width).normal_(0, 1), requires_grad=True)\n",
    "        u.data = l2normalize(u.data)\n",
    "        v.data = l2normalize(v.data)\n",
    "        w_bar = nn.Parameter(w.data, requires_grad=True)\n",
    "\n",
    "        del self.module._parameters[self.name]\n",
    "\n",
    "        self.module.register_parameter(self.name + \"_u\", u)\n",
    "        self.module.register_parameter(self.name + \"_v\", v)\n",
    "        self.module.register_parameter(self.name + \"_bar\", w_bar)\n",
    "\n",
    "\n",
    "    def forward(self, *args):\n",
    "        self._update_u_v()\n",
    "        return self.module.forward(*args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class snp_generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(snp_generator, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(15, 4)\n",
    "\n",
    "        self.fc = nn.Linear(100, 256*12*1)\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose2d(256, 128, kernel_size=(7, 1), stride=2,\n",
    "                         padding=(2, 0), bias=False)\n",
    "        self.cbn1 = CBN(4, 128, 128)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.ConvTranspose2d(128, 64, kernel_size=(8, 1), stride=2,\n",
    "                         padding=(3, 0), bias=False)\n",
    "        self.cbn2 = CBN(4, 128, 64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.ConvTranspose2d(64, 32, kernel_size=(8, 1), stride=2,\n",
    "                         padding=(3, 0), bias=False)\n",
    "        self.cbn3 = CBN(4, 128, 32)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.conv4 = nn.ConvTranspose2d(32, 1, kernel_size=(16, 4), stride=2,\n",
    "                         padding=(7, 0), bias=False)\n",
    "        self.softmax = nn.Softmax(dim=3)\n",
    "\n",
    "    def forward(self, nz, c):\n",
    "        embedding = self.embed(c)\n",
    "        h = self.fc(nz)\n",
    "        h = self.conv1(h.view(-1, 256, 12, 1))\n",
    "        h = self.cbn1(h, embedding)\n",
    "        h = self.relu1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.cbn2(h, embedding)\n",
    "        h = self.relu2(h)\n",
    "        h = self.conv3(h)\n",
    "        h = self.cbn3(h, embedding)\n",
    "        h = self.relu3(h)\n",
    "        h = self.conv4(h)\n",
    "        output = self.softmax(h)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class snp_discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(snp_discriminator, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(15, 8)\n",
    "\n",
    "#         self.conv1 = SpectralNorm(nn.Conv2d(1, 16, kernel_size=(11, 4), stride=1, padding=(5, 0), bias=False))\n",
    "#         self.lrelu1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "#         self.conv2 = SpectralNorm(nn.Conv2d(16, 32, kernel_size=(11, 1), stride=2, padding=(5, 0), bias=False))\n",
    "#         self.lrelu2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "#         self.conv3 = SpectralNorm(nn.Conv2d(32, 64, kernel_size=(11, 1), stride=2, padding=(5, 0), bias=False))\n",
    "#         self.lrelu3 = nn.LeakyReLU(0.2, inplace=True)\n",
    "#         self.conv4 = SpectralNorm(nn.Conv2d(64, 128, kernel_size=(11, 1), stride=2, padding=(5, 0), bias=False))\n",
    "#         self.lrelu4 = nn.LeakyReLU(0.2, inplace=True)\n",
    "#         self.pool = nn.AvgPool2d((25, 1))\n",
    "#         self.fc = SpectralNorm(nn.Linear(128, 1))\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.conv1 = SpectralNorm(nn.Conv2d(1, 320, kernel_size=(11, 4), stride=1, padding=(5, 0), bias=False))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(40, 1))\n",
    "        self.lrelu1 = nn.LeakyReLU(0.1, inplace=True)\n",
    "        self.fc1 = SpectralNorm(nn.Linear(320*5, 8))\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.lrelu2 = nn.LeakyReLU(0.1, inplace=True)\n",
    "        self.fc2 = SpectralNorm(nn.Linear(8, 1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        embedding = self.embed(c)\n",
    "        h = self.conv1(x.view(-1, 1, 200, 4))\n",
    "        h = self.pool1(h)\n",
    "#         h = self.bn1(h)\n",
    "        h = self.lrelu1(h)\n",
    "        h = self.fc1(h.view(-1, 320 * 5))\n",
    "        h = self.drop1(h)\n",
    "        h = self.lrelu2(h)\n",
    "#         h = self.bn2(h)\n",
    "        fc = self.fc2(h)\n",
    "#         h = self.conv1(x.view(-1, 1, 200, 4))\n",
    "#         h = self.lrelu1(h)\n",
    "#         h = self.conv2(h)\n",
    "#         h = self.lrelu2(h)\n",
    "#         h = self.conv3(h)\n",
    "#         h = self.lrelu3(h)\n",
    "#         h = self.conv4(h)\n",
    "#         h = self.lrelu4(h)\n",
    "#         pool = self.pool(h)\n",
    "#         fc = self.fc(pool.squeeze())\n",
    "        proj = torch.sum(h * embedding, 1, keepdim=True)\n",
    "        fc += proj\n",
    "        sig = self.sigmoid(fc)\n",
    "        return sig.squeeze()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = snp_generator().to(\"cuda\")\n",
    "D = snp_discriminator().to(\"cuda\")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NZ = 100\n",
    "NC = 15\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss().to(\"cuda\")\n",
    "optD = optim.Adam(D.parameters(), lr=0.0001, betas=(0.5, 0.99))\n",
    "optG = optim.Adam(G.parameters(), lr=0.0001, betas=(0.5, 0.99))\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.detach().normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.detach().normal_(1.0, 0.02)\n",
    "        m.bias.detach().fill_(0)\n",
    "\n",
    "G.apply(weights_init)\n",
    "\n",
    "train_hist = {}\n",
    "train_hist['d_loss'] = []\n",
    "train_hist['g_loss'] = []\n",
    "train_hist['epoch_time'] = []\n",
    "train_hist['total_time'] = []\n",
    "\n",
    "\n",
    "def create_fixed_inputs(num_total_imgs):\n",
    "    # For saving imgs\n",
    "    fixed_noise = torch.Tensor(num_total_imgs, NZ).normal_(0, 1).to(\"cuda\")\n",
    "\n",
    "    np_fixed_c = np.arange(0, NC, 1)\n",
    "    fixed_c = torch.from_numpy(np.repeat(np_fixed_c, num_total_imgs//NC, axis=0)).long().to(\"cuda\")\n",
    "\n",
    "    return fixed_noise, fixed_c\n",
    "\n",
    "\n",
    "def save_imgs(G, f_noise, f_c, it):\n",
    "    with torch.no_grad():\n",
    "        images = G(f_noise, f_c)\n",
    "    to_save = images.transpose(2, 3)\n",
    "    img_path = '/home/pbromley/generative_dhs/images/pytorch-sngan-dhs-200/%d.png' % it\n",
    "    vutils.save_image(to_save, img_path, nrow=1, normalize=True)\n",
    "    \n",
    "def accuracy(output, target):\n",
    "    \"\"\"Computes the accuracy for multiple binary predictions\"\"\"\n",
    "    pred = output >= 0.5\n",
    "    truth = target >= 0.5\n",
    "    acc = pred.eq(truth).sum().item() / target.numel()\n",
    "    return acc\n",
    "\n",
    "\n",
    "def train(G, D, iterations):\n",
    "    dataiter = iter(dhs_dataloader)\n",
    "    noise = torch.zeros(BATCH_SIZE, NZ).to(\"cuda\")\n",
    "    fake_c = torch.zeros(BATCH_SIZE).to(\"cuda\")\n",
    "    label = torch.zeros(BATCH_SIZE).to(\"cuda\")\n",
    "    fixed_noise, fixed_c = create_fixed_inputs(45)\n",
    "    neg_one = torch.FloatTensor([-1]).to(\"cuda\")\n",
    "    for iteration in range(iterations):\n",
    "        \n",
    "        ## GENERATOR ##\n",
    "        optG.zero_grad()\n",
    "        noise.normal_(0, 1)\n",
    "        label.fill_(1)\n",
    "        fake_c = torch.randint_like(fake_c, 0, NC).long()\n",
    "        fake = G(noise, fake_c)\n",
    "        pred_g = D(fake, fake_c)\n",
    "        g_loss = pred_g.mean()     ##\n",
    "        g_loss.backward(neg_one)   ##\n",
    "        optG.step()\n",
    "        \n",
    "        ## DISCRIMINATOR ##\n",
    "        for d_iter in range(5):\n",
    "            optD.zero_grad()\n",
    "            batch = next(dataiter, None)\n",
    "            if (batch is None) or (batch[0].size(0) != BATCH_SIZE):\n",
    "                dataiter = iter(dhs_dataloader)\n",
    "                batch = dataiter.next()\n",
    "            x, c = batch\n",
    "            x = x.float().to(\"cuda\")\n",
    "            c = c.long().to(\"cuda\")\n",
    "            label.fill_(1)\n",
    "            pred_real = D(x, c)\n",
    "            d_loss_real = pred_real.mean()  ##\n",
    "#             d_loss_real.backward()\n",
    "            \n",
    "            label.fill_(0)\n",
    "            noise.normal_(0, 1)\n",
    "            fake_c = torch.randint_like(fake_c, 0, NC).long()\n",
    "            fake = G(noise, fake_c)\n",
    "            pred_fake = D(fake.detach(), fake_c)\n",
    "            d_loss_fake = pred_fake.mean()  ##\n",
    "#             d_loss_fake.backward()\n",
    "\n",
    "            d_loss_total = d_loss_fake - d_loss_real ##\n",
    "            d_loss_total.backward() ##\n",
    "            \n",
    "            optD.step()\n",
    "            \n",
    "        if (iteration % 100 == 0):\n",
    "            \n",
    "#             acc_real = accuracy(pred_real, torch.ones(BATCH_SIZE).cuda())\n",
    "#             acc_fake = accuracy(pred_fake, torch.zeros(BATCH_SIZE).cuda())\n",
    "            print('Iter:{0}, Dloss: {1}, Gloss: {2}'.format(\n",
    "                            iteration, d_loss_total.item(), g_loss.item())\n",
    "                 )\n",
    "            if iteration % 1000 == 0:\n",
    "                save_imgs(G, fixed_noise, fixed_c, iteration)\n",
    "                \n",
    "            \n",
    "                        \n",
    "            \n",
    "train(G, D, 500000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/home/pbromley/generative_dhs/saved_models/pytorch-sngan-dhs-wgan-200\"\n",
    "# print(\"Saving Model Weights...\")\n",
    "# torch.save(G.state_dict(), path + \"-g.pth\")\n",
    "# torch.save(D.state_dict(), path + \"-d.pth\")\n",
    "# print(\"Saved Model Weights\")\n",
    "\n",
    "class snp_generator_2d(nn.Module):\n",
    "    def __init__(self, nz, ne, cbn_h, num_filters, len_filters, dropout=False, concat=False):\n",
    "        super(snp_generator_2d, self).__init__()\n",
    "\n",
    "        self.num_filters = num_filters\n",
    "\n",
    "        self.embed = nn.Embedding(15, ne)\n",
    "        self.fc = SpectralNorm(nn.Linear(nz, num_filters//2*10))\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "        self.cbn1 = CBN(ne, cbn_h, num_filters//2)\n",
    "        self.up1 = SpectralNorm(nn.ConvTranspose2d(num_filters//2, num_filters, (10, 1), 10, bias=False))    # -1, 320, 100, 1\n",
    "        self.relu2 = nn.ReLU(True)\n",
    "        self.cbn2 = CBN(ne, cbn_h, num_filters)\n",
    "        self.up2 = SpectralNorm(nn.ConvTranspose2d(num_filters, 1, (len_filters, 4), 1, (len_filters//2, 0)))\n",
    "        self.softmax = nn.Softmax(dim=3)\n",
    "\n",
    "    def forward(self, nz, c):\n",
    "        embedding = self.embed(c)\n",
    "        h = self.fc(nz).view(-1, self.num_filters//2, 10, 1)\n",
    "        h = self.relu1(h)\n",
    "        h = self.cbn1(h, embedding)\n",
    "        h = self.up1(h)\n",
    "        h = self.relu2(h)\n",
    "        h = self.cbn2(h, embedding)\n",
    "        h = self.up2(h)\n",
    "        output = self.softmax(h)\n",
    "        return output\n",
    "\n",
    "G = snp_generator_2d(100, 4, 256, 320, 17).to(\"cuda\")\n",
    "G.load_state_dict(torch.load(\"/home/pbromley/generative_dhs/saved_models/pytorch-sngan-hinge-dhs-100-2-g.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G.double()\n",
    "G.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.train(False)\n",
    "G.eval()\n",
    "one_hot_seqs = np.zeros((153600, 1, 100, 4))\n",
    "components = np.zeros(153600, dtype=int)\n",
    "for i in range(15):\n",
    "    for j in range(640):\n",
    "        noise = torch.from_numpy(np.random.normal(0, 1, (16, 100)))\n",
    "#         components = torch.from_numpy(np.ones(128, dtype=int)*i).long()\n",
    "        comps = torch.from_numpy(np.random.randint(0, 15, 16, dtype=int)).long()\n",
    "        with torch.no_grad():\n",
    "            one_hot_seqs[(i*10240) + (j*16):(i*10240) + ((j+1)*16)] = G(noise, comps).numpy()\n",
    "            components[(i*10240) + (j*16):(i*10240) + ((j+1)*16)] = comps\n",
    "\n",
    "one_hot_seqs = one_hot_seqs.reshape(-1, 100, 4)\n",
    "    \n",
    "def one_hot_to_seq(one_hot):\n",
    "    order_dict = {0:'A', 1:'T', 2:'C', 3:'G'}\n",
    "    seq = \"\"\n",
    "    idxs = np.argmax(one_hot, axis=1)\n",
    "    for elt in idxs:\n",
    "        seq += order_dict[elt]\n",
    "    return Seq(seq, single_letter_alphabet)\n",
    "\n",
    "print(\"Converting one-hot to normal...\")\n",
    "seqs = [one_hot_to_seq(one_hot_seq) for one_hot_seq in one_hot_seqs]\n",
    "# components = np.repeat(np.arange(0, 15), 20480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(np.arange(0, 5, 1), 45//5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [one_hot_to_seq(one_hot_seq) for one_hot_seq in x_train.squeeze()]\n",
    "components = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    noise = torch.from_numpy(np.random.normal(0, 1, (16, 100)))\n",
    "    comps = torch.from_numpy(np.random.randint(0, 15, 16, dtype=int)).long()\n",
    "    _ = G(noise, comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs = [\"GGCGC\", \"ATGAGTCAT\", \"CGAAACCGAAAC\", \"TGATGCAA\", \"ATGA\", \"ATTGT\",\n",
    "          \"AACCGGTT\", \"AATTA\", \"AAATAG\", \"GTCACGCTT\", \"GTAAACA\", \"AACAGCTGT\", \"CAAAGT\", \"CGGAT\",\n",
    "          \"ACTTCC\"]\n",
    "motifs = [Seq(motif, single_letter_alphabet) for motif in motifs]\n",
    "\n",
    "# def motif_search(seqs, components, motifs):\n",
    "count_dict = {num:np.zeros(15) for num in range(15)}\n",
    "print(\"Motif: \", end=\" \")\n",
    "for i, motif in enumerate(motifs):\n",
    "    print(str(i) + \":\" + motif, end=' ')\n",
    "    for j, seq in enumerate(seqs):\n",
    "        count_dict[components[j]][i] += seq.count(motif)\n",
    "\n",
    "count_mat = np.array(list(count_dict.values()))\n",
    "plt.xticks(np.arange(15), [str(x+1) for x in range(15)])\n",
    "plt.yticks(np.arange(15), [str(x+1) for x in range(15)])\n",
    "plt.imshow(count_mat/count_mat.max(axis=0), cmap='Greens')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Motifs (for each component)\")\n",
    "plt.ylabel(\"Sequences (separated by component)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "# motif_search(seqs, components, motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150)\n",
    "count_mat.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_overall_composition(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the avg A, T, C, G content per sequence for an array of sequences \n",
    "#  (output is np array of format [A/n, T/n, C/n, G/n] where n = len(seqs))\n",
    "def calc_overall_composition(seqs):\n",
    "    atcg = np.array([0, 0, 0, 0])\n",
    "    for seq in seqs:\n",
    "        atcg[0] += seq.count(\"A\")\n",
    "        atcg[1] += seq.count(\"T\")\n",
    "        atcg[2] += seq.count(\"C\")\n",
    "        atcg[3] += seq.count(\"G\")\n",
    "    return atcg / len(seqs)\n",
    "\n",
    "# Calculate (and plot) the avg A, T, C, G content per sequence in each component class \n",
    "#  Input: array of seqs and array of corresponding component class\n",
    "#  Output: dict of format Component:[A/n_c, T/n_c, C/n_c, G/n_c] where n_c = len(seqs from class c)\n",
    "#  If plot is true, plot the output as a bar graph of ATCG content across sequences by class\n",
    "def per_class_composition(seqs, c, plot=True):\n",
    "    num_c = np.max(c) + 1\n",
    "    comp_dict = {k:np.array([0, 0, 0, 0]) for k in range(num_c)}\n",
    "    for i in range(len(seqs)):\n",
    "        comp_dict[c[i]][0] += seqs[i].count(\"A\")\n",
    "        comp_dict[c[i]][1] += seqs[i].count(\"T\")\n",
    "        comp_dict[c[i]][2] += seqs[i].count(\"C\")\n",
    "        comp_dict[c[i]][3] += seqs[i].count(\"G\")\n",
    "    num_per_class = np.bincount(c.astype(int))\n",
    "    comp_dict = {k:v/num_per_class[k] for k, v in comp_dict.items()}\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        index = np.arange(num_c)\n",
    "        bar_width = 0.2\n",
    "        a = [comp_dict[i][0] for i in range(num_c)]\n",
    "        t = [comp_dict[i][1] for i in range(num_c)]\n",
    "        c = [comp_dict[i][2] for i in range(num_c)]\n",
    "        g = [comp_dict[i][3] for i in range(num_c)]\n",
    "        plt.bar(index, a, bar_width)\n",
    "        plt.bar(index + bar_width, t, bar_width)\n",
    "        plt.bar(index + 2*bar_width, c, bar_width)\n",
    "        plt.bar(index + 3*bar_width, g, bar_width)\n",
    "        \n",
    "    return comp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class_composition(seqs, components.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_array = []\n",
    "for i in range(len(seqs)):\n",
    "    seq_array.append(SeqRecord(seqs[i], id=str(components[i])))\n",
    "SeqIO.write(seq_array, \"/home/pbromley/generative_dhs/memes/fake_test_4.fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "128 * 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for the pytorch-sngan-dhs-100-siggenerator\n",
    "class snp_generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(snp_generator, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(15, 4)\n",
    "\n",
    "        self.fc = nn.Linear(100, 128*12*1)\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose2d(128, 64, kernel_size=(7, 1), stride=2,\n",
    "                         padding=(2, 0), bias=False)\n",
    "        self.cbn1 = CBN(4, 128, 64)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.ConvTranspose2d(64, 32, kernel_size=(8, 1), stride=2,\n",
    "                         padding=(3, 0), bias=False)\n",
    "        self.cbn2 = CBN(4, 128, 32)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.ConvTranspose2d(32, 1, kernel_size=(16, 4), stride=2,\n",
    "                         padding=(7, 0), bias=False)\n",
    "        self.softmax = nn.Softmax(dim=3)\n",
    "\n",
    "    def forward(self, nz, c):\n",
    "        embedding = self.embed(c)\n",
    "        h = self.fc(nz)\n",
    "        h = self.conv1(h.view(-1, 128, 12, 1))\n",
    "        h = self.cbn1(h, embedding)\n",
    "        h = self.relu1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.cbn2(h, embedding)\n",
    "        h = self.relu2(h)\n",
    "        h = self.conv3(h)\n",
    "        output = self.softmax(h)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for the pytorch-sngan-dhs-100-sig-1dg generator\n",
    "class snp_generator_1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(snp_generator_1d, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(15, 4)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, 100, 1, 1, bias=False)\n",
    "        self.cbn1 = CBN(4, 128, 100)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(100, 4, 11, 1, 5, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, nz, c):\n",
    "        embedding = self.embed(c)\n",
    "        h = self.conv1(nz.view(-1, 1, 100))\n",
    "        h = self.cbn1(h.view(-1, 100, 100, 1), embedding)\n",
    "        h = self.relu2(h.squeeze())\n",
    "        h = self.conv2(h)\n",
    "        output = self.softmax(h)\n",
    "        return output.transpose(1, 2).view(-1, 1, 100, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for the pytorch-sngan-dhs-100-sig-1dg-2 generator\n",
    "class snp_generator_1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(snp_generator_1d, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(15, 4)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, 200, 1, 1, bias=False)\n",
    "        self.cbn1 = CBN(4, 128, 200)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(200, 4, 1, 1, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, nz, c):\n",
    "        embedding = self.embed(c)\n",
    "        h = self.conv1(nz.view(-1, 1, 100))\n",
    "        h = self.cbn1(h.view(-1, 200, 100, 1), embedding)\n",
    "        h = self.relu2(h.squeeze())\n",
    "        h = self.conv2(h)\n",
    "        output = self.softmax(h)\n",
    "        return output.transpose(1, 2).view(-1, 1, 100, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class snp_generator_2(nn.Module):\n",
    "    def __init__(self, nz, ne, cbn_h, num_filters, len_filters, dropout=False, concat=False):\n",
    "        super(snp_generator_2, self).__init__()\n",
    "        \n",
    "        self.num_filters = num_filters\n",
    "\n",
    "        self.embed = nn.Embedding(15, ne)\n",
    "        self.fc = SpectralNorm(nn.Linear(nz, num_filters//2*10))\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "        self.cbn1 = CBN(ne, cbn_h, num_filters//2)\n",
    "        self.up1 = SpectralNorm(nn.ConvTranspose2d(num_filters//2, num_filters, (10, 1), 10, bias=False))    # -1, 320, 100, 1\n",
    "        self.relu2 = nn.ReLU(True)\n",
    "        self.cbn2 = CBN(ne, cbn_h, num_filters)\n",
    "        self.up2 = SpectralNorm(nn.ConvTranspose2d(num_filters, 1, (len_filters, 4), 1, (len_filters//2, 0)))\n",
    "        self.softmax = nn.Softmax(dim=3)\n",
    "\n",
    "    def forward(self, nz, c):\n",
    "        embedding = self.embed(c)\n",
    "        h = self.fc(nz).view(-1, self.num_filters//2, 10, 1)\n",
    "        h = self.relu1(h)\n",
    "        h = self.cbn1(h, embedding)\n",
    "        h = self.up1(h)\n",
    "        h = self.relu2(h)\n",
    "        h = self.cbn2(h, embedding)\n",
    "        h = self.up2(h)\n",
    "        output = self.softmax(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.ConvTranspose2d(160, 320, (10, 1), 10)\n",
    "y = nn.ConvTranspose2d(320, 1, (11, 4), 1, (5, 0))\n",
    "y(x(torch.rand(1, 160, 10, 1))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
